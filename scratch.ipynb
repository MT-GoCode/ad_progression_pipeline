{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tminh\\AppData\\Local\\Temp\\ipykernel_17708\\2759761197.py:4: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data6 = pd.read_csv(\"data6.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"seven_visits_train_new.csv\")\n",
    "data6 = pd.read_csv(\"data6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Perform the merge as before\n",
    "merged_df = pd.merge(data, data6, on=['NACCID', 'VISITDATE'], suffixes=('', '_6'))\n",
    "\n",
    "# Update columns that exist in both DataFrames\n",
    "common_columns = data.columns.intersection(data6.columns).drop(['NACCID', 'VISITDATE'])\n",
    "\n",
    "for col in common_columns:\n",
    "    data[col] = merged_df[col + '_6'].combine_first(data[col])\n",
    "\n",
    "# Clean up the extra columns from data6 that were added during the merge\n",
    "data = data[data.columns.drop(list(data.filter(regex='_6')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "giveaway_feats = ['MEMORY', 'ORIENT', 'JUDGMENT', 'COMMUN', 'HOMEHOBB', 'PERSCARE', 'CDRGLOB', 'NACCMMSE']\n",
    "time_feats = [\"VISITDATE\", \"COURSE\", \"VISITDAY\", \"VISITMO\", \"VISITYR\"]\n",
    "irrelevant_feats = ['visitorder',\n",
    " 'NACCUDSD',\n",
    " 'NACCDAYS',\n",
    " 'NACCMMSE',\n",
    " 'NACCAVST',\n",
    " 'NACCFDYS',\n",
    " '...7',\n",
    " 'NACCADC',\n",
    " 'interval',\n",
    " 'NACCVNUM',\n",
    " 'patient_id',]\n",
    "\n",
    "drop_feats = giveaway_feats + time_feats + irrelevant_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = drop_feats)\n",
    "data.to_csv('seven_visits_train_imputed_with_data6_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = data_filled.select_dtypes(exclude=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled.to_csv(\"fully_filled_seven_visits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NACCID', 'NACCAMS', 'PSYCDISX'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_na = data.isna().any()\n",
    "na_columns = data.columns[cols_with_na]\n",
    "cleaned = data.loc[:, ~cols_with_na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tminh\\AppData\\Local\\Temp\\ipykernel_19488\\4119197334.py:1: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  six = pd.read_csv('data6.csv')\n"
     ]
    }
   ],
   "source": [
    "six = pd.read_csv('data6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DECSUB...133',\n",
       " 'DECSUB...174',\n",
       " 'visit_number',\n",
       " 'cluster',\n",
       " 'var_cdrsum.x',\n",
       " 'classification.x',\n",
       " 'progression.x',\n",
       " 'var_cdrsum.y',\n",
       " 'classification.y',\n",
       " 'progression.y',\n",
       " 'var_cdrsum',\n",
       " 'classification',\n",
       " 'progression']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in six.columns if _ not in data.columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NACCID', 'VISITDATE', 'patient_id', 'NACCVNUM', 'NACCAVST', 'interval',\n",
       "       '...7', 'SEX', 'HISPANIC', 'HISPOR',\n",
       "       ...\n",
       "       'NACCUDSD', 'NACCDAYS', 'NACCFDYS', 'COURSE', 'VISITDAY', 'VISITMO',\n",
       "       'VISITYR', 'visitorder', 'NACCADC', 'IMPAIRMENTS'],\n",
       "      dtype='object', length=221)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>feature_col_A_1</th>\n",
       "      <th>feature_col_A_2</th>\n",
       "      <th>feature_col_A_3</th>\n",
       "      <th>feature_col_B_1</th>\n",
       "      <th>feature_col_B_2</th>\n",
       "      <th>feature_col_B_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>400</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NACCID  feature_col_A_1  feature_col_A_2  feature_col_A_3  feature_col_B_1  \\\n",
       "0       1               10               20               30              100   \n",
       "1       2               40               50               60              400   \n",
       "\n",
       "   feature_col_B_2  feature_col_B_3  \n",
       "0              200              300  \n",
       "1              500              600  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame setup\n",
    "data = {\n",
    "    'NACCID': [1, 1, 1, 2, 2, 2],\n",
    "    'constant_col_1': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'constant_col_2': ['X', 'X', 'X', 'Y', 'Y', 'Y'],\n",
    "    'feature_col_A': [10, 20, 30, 40, 50, 60],\n",
    "    'feature_col_B': [100, 200, 300, 400, 500, 600]\n",
    "}\n",
    "\n",
    "\n",
    "# List of constant columns\n",
    "CONSTANT_COLUMNS = ['NACCID', 'constant_col_1', 'constant_col_2']\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.loc[:, 'row_number'] = data.groupby('NACCID').cumcount() + 1\n",
    "flattened_df = data.pivot_table(index='NACCID', \n",
    "                                    columns='row_number', \n",
    "                                    values=data.columns.difference(CONSTANT_COLUMNS + ['row_number']))\n",
    "flattened_df.columns = [f'{col}_{num}' for col, num in flattened_df.columns]\n",
    "flattened_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tminh\\AppData\\Local\\Temp\\ipykernel_17708\\1552849762.py:1: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv('seven_visits_train_imputed_with_data6_temp.csv')['NACCID']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        NACC000034\n",
       "1        NACC000034\n",
       "2        NACC000034\n",
       "3        NACC000034\n",
       "4        NACC000034\n",
       "            ...    \n",
       "23725    NACC999854\n",
       "23726    NACC999854\n",
       "23727    NACC999854\n",
       "23728    NACC999854\n",
       "23729    NACC999854\n",
       "Name: NACCID, Length: 23730, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('seven_visits_train_imputed_with_data6_temp.csv')['NACCID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NACCID constant_col_1 constant_col_2  feature_col_A_1  feature_col_A_2  \\\n",
      "0       1              A              X               10               20   \n",
      "1       2              B              Y               40               50   \n",
      "\n",
      "   feature_col_A_3  feature_col_B_1  feature_col_B_2  feature_col_B_3  \n",
      "0               30              100              200              300  \n",
      "1               60              400              500              600  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'NACCID': [1, 1, 1, 2, 2, 2],\n",
    "    'constant_col_1': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'constant_col_2': ['X', 'X', 'X', 'Y', 'Y', 'Y'],\n",
    "    'feature_col_A': [10, 20, 30, 40, 50, 60],\n",
    "    'feature_col_B': [100, 200, 300, 400, 500, 600]\n",
    "}\n",
    "self_X = pd.DataFrame(data)\n",
    "\n",
    "CONSTANT_COLUMNS = ['constant_col_1', 'constant_col_2']\n",
    "\n",
    "result = self_X.groupby('NACCID').apply(lambda x: pd.Series({\n",
    "    **{col: x[col].iloc[0] for col in CONSTANT_COLUMNS},\n",
    "    **{f\"{col}_{i+1}\": x[col].iloc[i] for col in ['feature_col_A', 'feature_col_B'] for i in range(len(x))}\n",
    "})).reset_index()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_column_indices' from 'sklearn.utils' (C:\\Users\\tminh\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\combine\\_smote_enn.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\over_sampling\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\over_sampling\\_smote\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, OrdinalEncoder\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _get_column_indices,\n\u001b[0;32m     20\u001b[0m     _safe_indexing,\n\u001b[0;32m     21\u001b[0m     check_array,\n\u001b[0;32m     22\u001b[0m     check_random_state,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsefuncs_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     csr_mean_variance_axis0,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_features\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_get_column_indices' from 'sklearn.utils' (C:\\Users\\tminh\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Sample DataFrame and target column\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 1, 4, 5, 6],\n",
    "    'feature2': [3, 4, 2, 5, 6, 7],\n",
    "    'progression': [0, 1, 0, 0, 1, 0]\n",
    "})\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=['progression'])\n",
    "y = df['progression']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and fit the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00       273\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "                           weights=[0.1, 0.9], n_informative=3, \n",
    "                           n_redundant=1, flip_y=0, n_features=20, \n",
    "                           n_clusters_per_class=1, n_samples=1000, \n",
    "                           random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE and RandomForestClassifier\n",
    "smote = SMOTE(random_state=42)\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a pipeline with SMOTE and the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>HISPOR</th>\n",
       "      <th>RACE</th>\n",
       "      <th>PRIMLANG</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>NACCFAM</th>\n",
       "      <th>NACCMOM</th>\n",
       "      <th>NACCDAD</th>\n",
       "      <th>...</th>\n",
       "      <th>DIGBACLS_1</th>\n",
       "      <th>DIGBACLS_2</th>\n",
       "      <th>DIGBACLS_3</th>\n",
       "      <th>CDRSUM_1</th>\n",
       "      <th>CDRSUM_2</th>\n",
       "      <th>CDRSUM_3</th>\n",
       "      <th>IMPAIRMENTS_1</th>\n",
       "      <th>IMPAIRMENTS_2</th>\n",
       "      <th>IMPAIRMENTS_3</th>\n",
       "      <th>progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>3382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3383</th>\n",
       "      <td>3383</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>3387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>3388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>3389</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635 rows × 557 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  SEX  HISPANIC  HISPOR  RACE  PRIMLANG  EDUC  NACCFAM  \\\n",
       "0              0  2.0       0.0     8.0   1.0       1.0  15.0      1.0   \n",
       "1              1  1.0       1.0     4.0   6.0       2.0   4.0      1.0   \n",
       "2              2  2.0       0.0     8.0   5.0       1.0  20.0      1.0   \n",
       "4              4  1.0       0.0     8.0   1.0       1.0  14.0      0.0   \n",
       "5              5  2.0       0.0     8.0   1.0       1.0  18.0      1.0   \n",
       "...          ...  ...       ...     ...   ...       ...   ...      ...   \n",
       "3382        3382  1.0       0.0     8.0   1.0       1.0  18.0      1.0   \n",
       "3383        3383  2.0       0.0     8.0   1.0       1.0  13.0      1.0   \n",
       "3387        3387  2.0       0.0     8.0   1.0       1.0  14.0      1.0   \n",
       "3388        3388  2.0       0.0     8.0   1.0       1.0  18.0      1.0   \n",
       "3389        3389  2.0       0.0     8.0   1.0       7.0  20.0      0.0   \n",
       "\n",
       "      NACCMOM  NACCDAD  ...  DIGBACLS_1  DIGBACLS_2  DIGBACLS_3  CDRSUM_1  \\\n",
       "0         1.0      1.0  ...         4.0         4.0         4.0       0.5   \n",
       "1         0.0      0.0  ...         5.0         5.0         5.0      11.0   \n",
       "2         0.0      0.0  ...         6.0         5.0         5.0       0.0   \n",
       "4         0.0      0.0  ...         2.0         3.0         5.0       3.5   \n",
       "5         1.0      0.0  ...         5.0         5.0         5.0       0.0   \n",
       "...       ...      ...  ...         ...         ...         ...       ...   \n",
       "3382      1.0      0.0  ...         NaN         NaN         5.0       0.0   \n",
       "3383      1.0      0.0  ...         NaN         NaN         NaN       0.5   \n",
       "3387      1.0      1.0  ...         NaN         NaN         NaN       0.0   \n",
       "3388      1.0      1.0  ...         NaN         NaN         NaN       0.0   \n",
       "3389      0.0      0.0  ...         NaN         NaN         NaN       0.0   \n",
       "\n",
       "      CDRSUM_2  CDRSUM_3  IMPAIRMENTS_1  IMPAIRMENTS_2  IMPAIRMENTS_3  \\\n",
       "0          1.5       1.5            0.0            0.0            0.0   \n",
       "1         11.0       0.0            1.0            1.0            0.0   \n",
       "2          0.0       0.0            0.0            0.0            0.0   \n",
       "4          4.0       0.0            0.0            1.0            0.0   \n",
       "5          0.0       2.0            0.0            0.0            0.0   \n",
       "...        ...       ...            ...            ...            ...   \n",
       "3382       0.0       0.0            0.0            0.0            0.0   \n",
       "3383       0.0       0.5            0.0            0.0            0.0   \n",
       "3387       0.0       0.0            0.0            0.0            NaN   \n",
       "3388       0.0       0.0            0.0            0.0            NaN   \n",
       "3389       0.0       0.0            0.0            0.0            0.0   \n",
       "\n",
       "      progression  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "4               0  \n",
       "5               0  \n",
       "...           ...  \n",
       "3382            0  \n",
       "3383            0  \n",
       "3387            0  \n",
       "3388            0  \n",
       "3389            0  \n",
       "\n",
       "[2635 rows x 557 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('flattened_3.csv')\n",
    "df_filtered = df[df['progression'] == 0]\n",
    "df_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
